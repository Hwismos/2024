{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "\n",
    "import warnings\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import os\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid, WikipediaNetwork, Actor, WebKB, Amazon, Coauthor, WikiCS\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np \n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "import dgl\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset using pyg\n",
    "\n",
    "def load_data_with_pyg(dataset_name):\n",
    "    path = os.path.join('.', 'data', dataset_name)\n",
    "\n",
    "    if dataset_name in ['cora', 'citeseer', 'pubmed']:\n",
    "        dataset = Planetoid(path, dataset_name)\n",
    "    elif dataset_name in ['chameleon']:\n",
    "        dataset = WikipediaNetwork(path, dataset_name)\n",
    "    elif dataset_name in ['squirrel']:\n",
    "        dataset = WikipediaNetwork(path, dataset_name, transform=T.NormalizeFeatures())\n",
    "    elif dataset_name in ['actor']:\n",
    "        dataset = Actor(path)\n",
    "    elif dataset_name in ['cornell', 'texas', 'wisconsin']:\n",
    "        dataset = WebKB(path, dataset_name)\n",
    "    elif dataset_name in ['computers', 'photo']:\n",
    "        dataset = Amazon(path, dataset_name, transform=T.NormalizeFeatures())\n",
    "    elif dataset_name in ['cs', 'physics']:\n",
    "        dataset = Coauthor(path, dataset_name, transform=T.NormalizeFeatures())\n",
    "    elif dataset_name in ['wikics']:\n",
    "        dataset = WikiCS(path)\n",
    "\n",
    "    data = dataset[0]\n",
    "    return data\n",
    "\n",
    "name = 'pubmed'\n",
    "data = load_data_with_pyg(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialzie dataset dictionary which becomes dataset series later\n",
    "\n",
    "def get_dataset_dict(data):\n",
    "    edges_without_self_loops = remove_self_loops(data.edge_index)[0]\n",
    "\n",
    "    features = data.x\n",
    "    labels = data.y\n",
    "    num_nodes = len(labels) \n",
    "    num_edges = len(edges_without_self_loops[0])\n",
    "    dataset_dict = {'name': name, 'num_nodes': num_nodes, 'num_edges': num_edges,\n",
    "                    'features': features, 'labels': labels, \n",
    "                    'edges': edges_without_self_loops}\n",
    "\n",
    "    dataset_dict['src'] = dataset_dict['edges'][0]\n",
    "    dataset_dict['dst'] = dataset_dict['edges'][1]\n",
    "\n",
    "    dataset_dict['graph'] = dgl.graph((dataset_dict['src'], dataset_dict['dst']), \n",
    "                                      num_nodes=num_nodes, idtype=torch.int)\n",
    "\n",
    "    return dataset_dict\n",
    "\n",
    "dataset_dict = get_dataset_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate Label Informations and Adjusted Homophily\n",
    "\n",
    "def get_p_bar_k(dataset_dict):\n",
    "    labels = dataset_dict['labels']\n",
    "    num_edges = dataset_dict['num_edges']\n",
    "    num_nodes = dataset_dict['num_nodes']\n",
    "    degree_dict = defaultdict(int)\n",
    "    norm_degree_dict = defaultdict(int)\n",
    "\n",
    "    for node in range(num_nodes):\n",
    "        label = labels[node].item()\n",
    "        degrees = dataset_dict['graph'].in_degrees(node) + dataset_dict['graph'].out_degrees(node)\n",
    "        degree_dict[label] += degrees\n",
    "    for label, degree in degree_dict.items():\n",
    "        norm_degree_dict[label] = degree / (2 * num_edges)\n",
    "    \n",
    "    return norm_degree_dict\n",
    "\n",
    "\n",
    "def get_p_c1_and_c2(dataset_dict):\n",
    "    unique_labels = np.unique(dataset_dict['labels'])\n",
    "    unq_labels_product = list(itertools.product(unique_labels, repeat=2))\n",
    "    num_edges = dataset_dict['num_edges']\n",
    "\n",
    "    src = dataset_dict['src'].numpy()\n",
    "    dst = dataset_dict['dst'].numpy()\n",
    "    src_labels = []\n",
    "    dst_labels = []\n",
    "    \n",
    "\n",
    "    for v in src:\n",
    "        src_labels.append(dataset_dict['labels'][v].item())\n",
    "    for v in dst:\n",
    "        dst_labels.append(dataset_dict['labels'][v].item())\n",
    "\n",
    "    edge_label_pairs = list(zip(src_labels, dst_labels))\n",
    "    label_pairs_dict = defaultdict(int)\n",
    "    norm_label_pairs_dict = defaultdict(int)\n",
    "\n",
    "    for product in unq_labels_product:\n",
    "        c1, c2 = product\n",
    "        for edge_label_pair in edge_label_pairs:\n",
    "            y_u, y_v = edge_label_pair\n",
    "            if y_u == c1 and y_v == c2:\n",
    "                label_pairs_dict[(c1, c2)] += 1\n",
    "    for pair, cnt in label_pairs_dict.items():\n",
    "        norm_label_pairs_dict[pair] = cnt / (num_edges)\n",
    "\n",
    "    return norm_label_pairs_dict\n",
    "\n",
    "\n",
    "def get_p_k(dataset_dict):\n",
    "    labels = list(dataset_dict['labels'].numpy())\n",
    "    edges_num = dataset_dict['num_edges']\n",
    "    nodes_num = dataset_dict['num_nodes']\n",
    "    label_dict = defaultdict(int)\n",
    "    norm_label_dict = defaultdict(int)\n",
    "\n",
    "    for label in np.unique(labels):\n",
    "        label_dict[label] = labels.count(label)\n",
    "    for label, cnt in label_dict.items():\n",
    "        norm_label_dict[label] = cnt / nodes_num\n",
    "    \n",
    "    return norm_label_dict\n",
    "\n",
    "\n",
    "def check_summation(norm_degree_dict, norm_label_dict, norm_label_pairs_dict):\n",
    "    checker_dict = defaultdict(int)\n",
    "    checker_dict['sum_of_degree'] = {sum(norm_degree_dict.values())}\n",
    "    checker_dict['sum_of_num_class'] = {sum(norm_label_dict.values())}\n",
    "    checker_dict['sum_of_class_pairs'] = {sum(norm_label_pairs_dict.values())}\n",
    "\n",
    "    return checker_dict\n",
    "\n",
    "\n",
    "def calc_label_information(dataset_dict):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "\n",
    "    norm_degree_dict = get_p_bar_k(dataset_dict)\n",
    "    norm_label_dict = get_p_k(dataset_dict)\n",
    "    norm_label_pairs_dict = get_p_c1_and_c2(dataset_dict)\n",
    "\n",
    "    checker_dict = check_summation(norm_degree_dict, norm_label_dict, norm_label_pairs_dict)\n",
    "\n",
    "    for c1_c2, p_c1_c2 in norm_label_pairs_dict.items():\n",
    "        c1, c2 = c1_c2\n",
    "        p_bar_c1 = norm_degree_dict[c1]\n",
    "        p_bar_c2 = norm_degree_dict[c2]\n",
    "        numerator += p_c1_c2 * math.log2(p_c1_c2 / (p_bar_c1 * p_bar_c2))\n",
    "    for p_bar_c in norm_degree_dict.values():\n",
    "        denominator += p_bar_c * math.log2(p_bar_c)\n",
    "\n",
    "    label_information = - (numerator / denominator)\n",
    "\n",
    "    return label_information, checker_dict\n",
    "\n",
    "\n",
    "def calc_edge_homophily(dataset_dict):   # yandex_dataloader\n",
    "    src = dataset_dict['src'].numpy()\n",
    "    dst = dataset_dict['dst'].numpy()\n",
    "    pairs = list(zip(src, dst))\n",
    "    labels = dataset_dict['labels'].numpy()\n",
    "\n",
    "    homophily_count = 0\n",
    "    for pair in pairs:\n",
    "        u, v = pair\n",
    "        if labels[u] == labels[v]:\n",
    "            homophily_count += 1\n",
    "\n",
    "    edge_homophily = homophily_count / len(src)\n",
    "    return edge_homophily\n",
    "\n",
    "\n",
    "def calc_adjusted_homophily(dataset_dict):  # yandex_dataloader\n",
    "    label_degree_cnt = defaultdict(int)\n",
    "    labels = dataset_dict['labels'].numpy()\n",
    "\n",
    "    for node in range(len(labels)):\n",
    "        label = labels[node]\n",
    "        degree = (dataset_dict['graph'].in_degrees(node) + dataset_dict['graph'].out_degrees(node))\n",
    "        label_degree_cnt[label] += degree  # D_k\n",
    "\n",
    "    total = 0\n",
    "    num_edges = dataset_dict['num_edges']\n",
    "    num_edges = (2 * num_edges) * (2 * num_edges)\n",
    "\n",
    "    for degree_cnt in label_degree_cnt.values():\n",
    "        degree_cnt = degree_cnt * degree_cnt\n",
    "        total += (degree_cnt / num_edges)\n",
    "\n",
    "    edge_hm = calc_edge_homophily(dataset_dict)\n",
    "    adjusted_homophily = (edge_hm - total) / (1.0 - total)\n",
    "    return adjusted_homophily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataset dictionary\n",
    "\n",
    "label_information, checker_dict = calc_label_information(dataset_dict)\n",
    "\n",
    "for value in checker_dict.values():\n",
    "    print(value.pop)\n",
    "    print(type(value.pop))\n",
    "    # if value.pop < 0.9:\n",
    "    #     print('Something is wrong!!!')\n",
    "    #     assert(False)    \n",
    "\n",
    "edge_homophily = calc_edge_homophily(dataset_dict)\n",
    "adjusted_homophily = calc_adjusted_homophily(dataset_dict)\n",
    "\n",
    "dataset_dict['label_information'] = label_information\n",
    "dataset_dict['edge_homo'] = edge_homophily\n",
    "dataset_dict['adjusted_homo'] = adjusted_homophily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset series \n",
    "\n",
    "def get_series(dataset_dict):\n",
    "    keys = dataset_dict.keys()\n",
    "    values = dataset_dict.values()\n",
    "    df = pd.Series(values, index=keys)\n",
    "    return df\n",
    "\n",
    "ser = get_series(dataset_dict)\n",
    "ser.drop(labels=['features', 'labels', 'edges', \n",
    "                            'src', 'dst', 'graph'], \n",
    "                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with series\n",
    "\n",
    "ser_cora = pd.read_csv('series_cora.csv')\n",
    "ser_citeseer = pd.read_csv('series_citeseer.csv')\n",
    "ser_pubmed = pd.read_csv('series_pubmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert series to dataframe and then merge dataframes\n",
    "\n",
    "def get_dataframe_from_series(ser):\n",
    "    index_list = []\n",
    "    value_list = []\n",
    "    column_list = []\n",
    "\n",
    "    for row in ser.values:\n",
    "        key, value = row\n",
    "        if key == 'name':\n",
    "            column_list.append(value)\n",
    "            continue\n",
    "        else:\n",
    "            index_list.append(key)\n",
    "        value_list.append(value)\n",
    "\n",
    "    return pd.DataFrame(value_list, index=index_list, columns=column_list)\n",
    "\n",
    "\n",
    "def merge_dataframes(df_list, axis=1):\n",
    "    return pd.concat(df_list, axis=axis)\n",
    "\n",
    "\n",
    "df_cora = get_dataframe_from_series(ser_cora)\n",
    "df_citeseer = get_dataframe_from_series(ser_citeseer)\n",
    "df_pubmed = get_dataframe_from_series(ser_pubmed)\n",
    "\n",
    "df_lists = [df_cora, df_citeseer, df_pubmed]\n",
    "df = merge_dataframes(df_lists)\n",
    "\n",
    "df_homo = df.T\n",
    "\n",
    "hetero_graph_csv_path = '/home/hwiric/2024/projects/240116_AdjHomo_LabelInfo/statistics.csv'\n",
    "df_hetero = pd.read_csv(hetero_graph_csv_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot label information of total graphs with matplotlib\n",
    "\n",
    "def plot_comparison_of_label_info(list_indicies, list_label_info):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # It start to plot from bottom \n",
    "    ax.barh(list_indicies, list_label_info, \n",
    "           label=list(zip(list_indicies, list_label_info)), \n",
    "           color=sns.color_palette('hls', len(list_indicies)))\n",
    "\n",
    "    ax.set_ylabel('Datasets')\n",
    "    ax.set_title('Label Information of Graphs')\n",
    "    h, l = ax.get_legend_handles_labels()\n",
    "    ax.legend(title='Label Information',\n",
    "              loc=\"upper left\", bbox_to_anchor=(1.01, 1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "label_info_homo = list(map(lambda x: round(x, 3), df_homo['label_information'].values.astype(float)))\n",
    "label_info_hetero = list(map(lambda x: round(x, 3), df_hetero['label_info'].values.astype(float)))\n",
    "list_label_info = label_info_homo + label_info_hetero\n",
    "\n",
    "index_homo = df_homo.index.values\n",
    "index_hetero = df_hetero.index.values\n",
    "list_indicies = np.concatenate((index_homo, index_hetero), axis=0)\n",
    "\n",
    "# Sort label information and then feed it to plot function\n",
    "\n",
    "dict_data_linfo = dict(zip(list_indicies, list_label_info))\n",
    "list_sorted = sorted(dict_data_linfo.items(), key = lambda item: item[1])\n",
    "list_data_linfo = [[i for i, j in list_sorted],\n",
    "\t\t\t\t [j for i, j in list_sorted]]\n",
    "\n",
    "plot_comparison_of_label_info(list_data_linfo[0], list_data_linfo[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot according to adjusted homophily values\n",
    "\n",
    "def plot_comparison_of_adj_homo(list_indicies, list_label_info):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # It start to plot from bottom \n",
    "    ax.barh(list_indicies, list_label_info, \n",
    "           label=list(zip(list_indicies, list_label_info)), \n",
    "           color=sns.color_palette('hls', len(list_indicies)))\n",
    "\n",
    "    ax.set_ylabel('Datasets')\n",
    "    ax.set_title('Adjusted Homophily of Graphs')\n",
    "    h, l = ax.get_legend_handles_labels()\n",
    "    ax.legend(title='Adjusted Homophily',\n",
    "              loc=\"upper left\", bbox_to_anchor=(1.01, 1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "adj_hm_homo = list(map(lambda x: round(x, 3), df_homo['adjusted_homo'].values.astype(float)))\n",
    "adj_hm_hetero = list(map(lambda x: round(x, 3), df_hetero['adj_homo'].values.astype(float)))\n",
    "\n",
    "index_homo = df_homo.index.values\n",
    "index_hetero = df_hetero.index.values\n",
    "list_indicies = np.concatenate((index_homo, index_hetero), axis=0)\n",
    "\n",
    "list_adj_hm = adj_hm_homo + adj_hm_hetero\n",
    "\n",
    "dict_data_adj_hm = dict(zip(list_indicies, list_adj_hm))\n",
    "list_sorted = sorted(dict_data_adj_hm.items(), key = lambda item: item[1])\n",
    "list_data_adj_hm = [[i for i, j in list_sorted],\n",
    "\t\t\t\t [j for i, j in list_sorted]]\n",
    "\n",
    "plot_comparison_of_adj_homo(list_data_adj_hm[0], list_data_adj_hm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot according to edge homophily values\n",
    "\n",
    "def plot_comparison_of_edge_homo(list_indicies, list_label_info):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # It start to plot from bottom \n",
    "    ax.barh(list_indicies, list_label_info, \n",
    "           label=list(zip(list_indicies, list_label_info)), \n",
    "           color=sns.color_palette('hls', len(list_indicies)))\n",
    "\n",
    "    ax.set_ylabel('Datasets')\n",
    "    ax.set_title('Edge Homophily of Graphs')\n",
    "    h, l = ax.get_legend_handles_labels()\n",
    "    ax.legend(title='Edge Homophily',\n",
    "              loc=\"upper left\", bbox_to_anchor=(1.01, 1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "edge_hm_homo = list(map(lambda x: round(x, 3), df_homo['edge_homo'].values.astype(float)))\n",
    "edge_hm_hetero = list(map(lambda x: round(x, 3), df_hetero['edge_homo'].values.astype(float)))\n",
    "\n",
    "index_homo = df_homo.index.values\n",
    "index_hetero = df_hetero.index.values\n",
    "list_indicies = np.concatenate((index_homo, index_hetero), axis=0)\n",
    "\n",
    "list_edge_hm = edge_hm_homo + edge_hm_hetero\n",
    "\n",
    "dict_data_edge_hm = dict(zip(list_indicies, list_edge_hm))\n",
    "list_sorted = sorted(dict_data_edge_hm.items(), key = lambda item: item[1])\n",
    "list_data_edge_hm = [[i for i, j in list_sorted],\n",
    "\t\t\t\t [j for i, j in list_sorted]]\n",
    "\n",
    "plot_comparison_of_edge_homo(list_data_edge_hm[0], list_data_edge_hm[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "240116_IPYNB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
