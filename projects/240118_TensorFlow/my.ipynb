{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch를 이용한 CUDA와 CUDNN 버전 확인\n",
    "import torch.__config__\n",
    "\n",
    "env_info = torch.__config__.show()\n",
    "with open('torch.txt', 'w') as f:\n",
    "    f.write(env_info)\n",
    "\n",
    "'''\n",
    "PyTorch built with:\n",
    "  - GCC 9.3\n",
    "  - C++ Version: 201402\n",
    "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
    "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
    "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
    "  - LAPACK is enabled (usually provided by MKL)\n",
    "  - NNPACK is enabled\n",
    "  - CPU capability usage: AVX2\n",
    "  - CUDA Runtime 11.3\n",
    "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
    "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
    "  - Magma 2.5.2\n",
    "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
    "'''\n",
    "\n",
    "# TF를 이용한 GPU 확인\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "'''\n",
    "2024-01-18 14:19:44.193123: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
    "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2024-01-18 14:19:50.288599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 6627 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:04:00.0, compute capability: 7.5\n",
    "2024-01-18 14:19:50.289861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:1 with 6627 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:05:00.0, compute capability: 7.5\n",
    "2024-01-18 14:19:50.290916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:2 with 6627 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
    "2024-01-18 14:19:50.291949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:3 with 6627 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
    "2024-01-18 14:19:50.292956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:4 with 6627 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:83:00.0, compute capability: 7.5\n",
    "2024-01-18 14:19:50.293975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:5 with 6627 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:84:00.0, compute capability: 7.5\n",
    "2024-01-18 14:19:50.294944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:6 with 6627 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:87:00.0, compute capability: 7.5\n",
    "2024-01-18 14:19:50.295969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:7 with 6627 MB memory:  -> device: 7, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:88:00.0, compute capability: 7.5\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow memory message 구분\n",
    "def print_color_line():\n",
    "    print(f\"\\033[0;30;41m==============================================================================================================================================================================================================================\\033[0m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "240118_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
