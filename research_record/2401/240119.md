# 240119

- 1월 여섯 번째 랩미팅 완료

- '우수학회' 관련 산단의 공지는 '학술지' 기준이었기 때문에 관련 없음

- 다음 미팅은 다음 주 목요일 13시로, 전날까지 연구장려금을 얻기 위한 proposal(연구계획서)를 작성해야 함

- LHT는 클러스터링 관련 연구는 접고 Disentagled 매커니즘에 direction 고려 알고리즘을 적용할 것을 탐구한다고 함 

- 본인은 ACM을 기본 베이스로 잡고 yandex에서 제시한 데이터셋에서도 잘 돌아가는 Transformed ACM을 만드는 것을 계획하였음 

- 하지만 ACM이 leakage가 발생한 squirrel, chameleon에서도 상당히 우수한 성능을 보였다는 점은 명백한 사실이고, 해당 데이터에 대해 어떻게 학습을 하였길래 그런 결과가 나온 것인지를 이해할 필요가 있다고 교수님께서 말씀 하셨음 

    - 해당 원인을 파악한다면 수정, 탈부착 등 부가적인 작업이 가능해질 수도 있음 

- Seperated GAT는 yandex 팀이 제시한 데이터셋 중 가장 robust한 성능을 보였음 

    - 이 모델이 비단 heterophily dataset에서만 잘 되는 것인지는 확인해볼 가치가 있음 

- 교수 간의 리그에서 교수님(지도 교수님)은 proposal 심사에서 떨어진 적이 없다고 하심

    - 이는 교수님의 방법을 이용하면 석사 연구장려금 지원에서 붙을 확률이 올라감을 의미함

    - 해당 연구계획서를 보고 선정하는 '교수의 입장'을 고려하여 작성해야 함

    - 연구계획서에서 아래의 두 가지 느낌을 독자에게 전달하는 것이 중요하다고 이야기 하심 
    
        - `이미 많이 진행되었다는 느낌`
        
        - `이미 실험은 대강 되어 있으니 돈을 준다면 충분히 가능할 것 같은 느낌`
    
    - 뿐만 아니라 이번 연구계획서를 쓰며 연구 PLAN을 세워보는 것도 도움이 될 것 같다고 이야기하심

    - 그래프 데이터의 범용성을 강조하면 좋을 것 같다고 이야기하심

- 학부생들 연구에 관련된 내용도 금일 미팅에서 들을 수 있었음 

    - 3인 팀의 경우 `Degree-based stratification of nodes in Graph Neural Networks`을 기반으로 연구를 진행하고 있음 

        - 코드가 없어 GAT 코드를 직접 위 논문에서 제시한 알고리즘에 맞게 구현하였다고 함 

        - degree에 따른 상이한 인코더를 통해 학습하는 것이 효과적이라는 것이 위 논문의 핵심 주장
    
    - 2인 팀의 경우 `GREET`을 기반으로 연구를 진행하고 있음 

        - 여러(3) 개의 판별기로부터 생성한 뷰로부터 ranking loss를 계산, 가장 loss가 작은 판별기 둘을 합쳐 view를 생성하는 아이디어를 구현하였음 

        - 랜덤성에 크게 의존하고 있음 

- cora, citeseer, pubmed의 label information과 adj, edge homophily 값을 측정 및 시각화하고 해당 프로젝트를 마무리함 